{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ab6ed3-7478-4703-b332-0ddadecb0435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T00:51:47.645186Z",
     "iopub.status.busy": "2022-08-31T00:51:47.644869Z",
     "iopub.status.idle": "2022-08-31T00:51:48.220019Z",
     "shell.execute_reply": "2022-08-31T00:51:48.219374Z",
     "shell.execute_reply.started": "2022-08-31T00:51:47.645121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 31 00:51:47 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  RTX A4000           Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 41%   37C    P8    14W / 140W |      0MiB / 16117MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838221e1-08d4-47f7-b863-35edf29cafb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T00:51:48.221433Z",
     "iopub.status.busy": "2022-08-31T00:51:48.221233Z",
     "iopub.status.idle": "2022-08-31T00:52:03.249915Z",
     "shell.execute_reply": "2022-08-31T00:52:03.249068Z",
     "shell.execute_reply.started": "2022-08-31T00:51:48.221416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers==0.2.4\n",
      "  Downloading diffusers-0.2.4-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from diffusers==0.2.4) (2022.7.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from diffusers==0.2.4) (2.28.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from diffusers==0.2.4) (1.23.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (from diffusers==0.2.4) (4.12.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from diffusers==0.2.4) (9.2.0)\n",
      "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.9/dist-packages (from diffusers==0.2.4) (1.12.0+cu116)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from diffusers==0.2.4) (3.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from diffusers==0.2.4) (0.8.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (21.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata->diffusers==0.2.4) (3.8.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->diffusers==0.2.4) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.2.4) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.2.4) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->diffusers==0.2.4) (2019.11.28)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.8.1->diffusers==0.2.4) (3.0.9)\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.2.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.20.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (1.8.1)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Installing collected packages: ftfy\n",
      "Successfully installed ftfy-6.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting gradio\n",
      "  Downloading gradio-3.1.7-py3-none-any.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.3.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.64.0)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from gradio) (1.9.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from gradio) (2022.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from gradio) (2.28.1)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from gradio) (1.4.3)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.8.0-cp39-cp39-manylinux_2_28_x86_64.whl (146 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets\n",
      "  Downloading websockets-10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.3/111.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.9/dist-packages (from gradio) (3.1.2)\n",
      "Collecting markdown-it-py[linkify,plugins]\n",
      "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting analytics-python\n",
      "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from gradio) (9.2.0)\n",
      "Collecting h11<0.13,>=0.11\n",
      "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting paramiko\n",
      "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading fastapi-0.81.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn\n",
      "  Downloading uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from gradio) (3.8.1)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from gradio) (3.5.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from gradio) (1.23.1)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->gradio) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->gradio) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->gradio) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->gradio) (2.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (18.2.0)\n",
      "Collecting backoff==1.10.0\n",
      "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.9/dist-packages (from analytics-python->gradio) (2.8.2)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from analytics-python->gradio) (1.14.0)\n",
      "Collecting starlette==0.19.1\n",
      "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette==0.19.1->fastapi->gradio) (3.6.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (1.2.0)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore<0.16.0,>=0.15.0\n",
      "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2->gradio) (2.1.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting mdit-py-plugins\n",
      "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting linkify-it-py~=1.0\n",
      "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (4.34.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (1.4.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->gradio) (2022.1)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-4.0.0-cp36-abi3-manylinux_2_28_x86_64.whl (594 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.4/594.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cryptography>=2.5\n",
      "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn->gradio) (8.1.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n",
      "Building wheels for collected packages: ffmpy, python-multipart\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=9fcdf2c8d38442a112cd9359673e08aa307bd9865a36a999ebc8e43a9be47411\n",
      "  Stored in directory: /root/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "  Building wheel for python-multipart (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31670 sha256=2b4542cd172c48b3c95c962f38661ba16f1e9e7cabac66c4c2c4f2c7c78f6c4a\n",
      "  Stored in directory: /root/.cache/pip/wheels/fe/04/d1/a10661cc45f03c3cecda50deb2d2c22f57b4e84a75b2a5987e\n",
      "Successfully built ffmpy python-multipart\n",
      "Installing collected packages: rfc3986, pydub, monotonic, ffmpy, websockets, uc-micro-py, python-multipart, pycryptodome, orjson, mdurl, h11, bcrypt, backoff, uvicorn, starlette, pynacl, markdown-it-py, linkify-it-py, httpcore, cryptography, analytics-python, paramiko, mdit-py-plugins, httpx, fastapi, gradio\n",
      "Successfully installed analytics-python-1.4.0 backoff-1.10.0 bcrypt-4.0.0 cryptography-37.0.4 fastapi-0.81.0 ffmpy-0.3.0 gradio-3.1.7 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.0 mdurl-0.1.2 monotonic-1.6 orjson-3.8.0 paramiko-2.11.0 pycryptodome-3.15.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 starlette-0.19.1 uc-micro-py-1.0.1 uvicorn-0.18.3 websockets-10.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: Cython in /usr/local/lib/python3.9/dist-packages (0.29.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install diffusers==0.2.4\n",
    "!pip install transformers scipy ftfy\n",
    "!pip install gradio datasets tqdm\n",
    "!pip3 install Cython\n",
    "!mkdir /root/.huggingface\n",
    "!echo -n \"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\" > /root/.huggingface/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a576b7d0-202e-4b8a-afb6-2482c149e9d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T00:52:03.252561Z",
     "iopub.status.busy": "2022-08-31T00:52:03.252364Z",
     "iopub.status.idle": "2022-08-31T00:55:34.186893Z",
     "shell.execute_reply": "2022-08-31T00:55:34.186309Z",
     "shell.execute_reply.started": "2022-08-31T00:52:03.252542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f8c8714e474d34b0898982c5f78050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0710f4455f492595efd3d0dc51f303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8916695fd524721aaea07d062e5b199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769db31817844756bcf896ef82f81558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/543 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af273bfdb78e42aab59d88376361fe94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94379e57fbcb4dddb16be5fe6a694fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/608M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67ddcd979024423aab6ea0b6e1ded3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/209 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c4ce91117a46b8afab0e4a30d92e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/209 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3d0534fa2c4af69615adb7a045c077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/572 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ecfa8147164685944ca408888d7f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66878f5207944e85a1e3e9f54a38296f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/71.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64fe68770e84cddadc5d52be857cc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/550 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2c8d7c24d348d7808a2dcc66c0995d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#disable nsfw filter\n",
    "with open('/usr/local/lib/python3.9/dist-packages/diffusers/pipelines/stable_diffusion/safety_checker.py','w') as file:\n",
    "  file.write('''import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import CLIPConfig, CLIPVisionModel, PreTrainedModel\n",
    "\n",
    "from ...utils import logging\n",
    "\n",
    "\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "\n",
    "def cosine_distance(image_embeds, text_embeds):\n",
    "    normalized_image_embeds = nn.functional.normalize(image_embeds)\n",
    "    normalized_text_embeds = nn.functional.normalize(text_embeds)\n",
    "    return torch.mm(normalized_image_embeds, normalized_text_embeds.T)\n",
    "\n",
    "\n",
    "class StableDiffusionSafetyChecker(PreTrainedModel):\n",
    "    config_class = CLIPConfig\n",
    "\n",
    "    def __init__(self, config: CLIPConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.vision_model = CLIPVisionModel(config.vision_config)\n",
    "        self.visual_projection = nn.Linear(config.vision_config.hidden_size, config.projection_dim, bias=False)\n",
    "\n",
    "        self.concept_embeds = nn.Parameter(torch.ones(17, config.projection_dim), requires_grad=False)\n",
    "        self.special_care_embeds = nn.Parameter(torch.ones(3, config.projection_dim), requires_grad=False)\n",
    "\n",
    "        self.register_buffer(\"concept_embeds_weights\", torch.ones(17))\n",
    "        self.register_buffer(\"special_care_embeds_weights\", torch.ones(3))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, clip_input, images):\n",
    "        pooled_output = self.vision_model(clip_input)[1]  # pooled_output\n",
    "        image_embeds = self.visual_projection(pooled_output)\n",
    "\n",
    "        special_cos_dist = cosine_distance(image_embeds, self.special_care_embeds).cpu().numpy()\n",
    "        cos_dist = cosine_distance(image_embeds, self.concept_embeds).cpu().numpy()\n",
    "\n",
    "        result = []\n",
    "        batch_size = image_embeds.shape[0]\n",
    "        for i in range(batch_size):\n",
    "            result_img = {\"special_scores\": {}, \"special_care\": [], \"concept_scores\": {}, \"bad_concepts\": []}\n",
    "\n",
    "            # increase this value to create a stronger `nfsw` filter\n",
    "            # at the cost of increasing the possibility of filtering benign images\n",
    "            adjustment = 0.0\n",
    "\n",
    "            for concet_idx in range(len(special_cos_dist[0])):\n",
    "                concept_cos = special_cos_dist[i][concet_idx]\n",
    "                concept_threshold = self.special_care_embeds_weights[concet_idx].item()\n",
    "                result_img[\"special_scores\"][concet_idx] = round(concept_cos - concept_threshold + adjustment, 3)\n",
    "                if result_img[\"special_scores\"][concet_idx] > 0:\n",
    "                    result_img[\"special_care\"].append({concet_idx, result_img[\"special_scores\"][concet_idx]})\n",
    "                    adjustment = 0.01\n",
    "\n",
    "            for concet_idx in range(len(cos_dist[0])):\n",
    "                concept_cos = cos_dist[i][concet_idx]\n",
    "                concept_threshold = self.concept_embeds_weights[concet_idx].item()\n",
    "                result_img[\"concept_scores\"][concet_idx] = round(concept_cos - concept_threshold + adjustment, 3)\n",
    "                if result_img[\"concept_scores\"][concet_idx] > 0:\n",
    "                    result_img[\"bad_concepts\"].append(concet_idx)\n",
    "\n",
    "            result.append(result_img)\n",
    "\n",
    "        has_nsfw_concepts = [len(res[\"bad_concepts\"]) > 0 for res in result]\n",
    "\n",
    "        #for idx, has_nsfw_concept in enumerate(has_nsfw_concepts):\n",
    "        #    if has_nsfw_concept:\n",
    "        #        images[idx] = np.zeros(images[idx].shape)  # black image\n",
    "\n",
    "        if any(has_nsfw_concepts):\n",
    "            logger.warning(\n",
    "                \"Potential NSFW content was detected in one or more images. A black image will be returned instead.\"\n",
    "                \" Try again with a different prompt and/or seed.\"\n",
    "            )\n",
    "\n",
    "        return images, has_nsfw_concepts''')\n",
    "import inspect\n",
    "import warnings\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import autocast\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    DDIMScheduler,\n",
    "    DiffusionPipeline,\n",
    "    PNDMScheduler,\n",
    "    UNet2DConditionModel,\n",
    ")\n",
    "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
    "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
    "class StableDiffusionImg2ImgPipeline(DiffusionPipeline):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vae: AutoencoderKL,\n",
    "        text_encoder: CLIPTextModel,\n",
    "        tokenizer: CLIPTokenizer,\n",
    "        unet: UNet2DConditionModel,\n",
    "        scheduler: Union[DDIMScheduler, PNDMScheduler],\n",
    "        safety_checker: StableDiffusionSafetyChecker,\n",
    "        feature_extractor: CLIPFeatureExtractor,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        scheduler = scheduler.set_format(\"pt\")\n",
    "        self.register_modules(\n",
    "            vae=vae,\n",
    "            text_encoder=text_encoder,\n",
    "            tokenizer=tokenizer,\n",
    "            unet=unet,\n",
    "            scheduler=scheduler,\n",
    "            safety_checker=safety_checker,\n",
    "            feature_extractor=feature_extractor,\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(\n",
    "        self,\n",
    "        prompt: Union[str, List[str]],\n",
    "        init_image: torch.FloatTensor,\n",
    "        strength: float = 0.8,\n",
    "        num_inference_steps: Optional[int] = 50,\n",
    "        guidance_scale: Optional[float] = 7.5,\n",
    "        eta: Optional[float] = 0.0,\n",
    "        generator: Optional[torch.Generator] = None,\n",
    "        output_type: Optional[str] = \"pil\",\n",
    "    ):\n",
    "\n",
    "        if isinstance(prompt, str):\n",
    "            batch_size = 1\n",
    "        elif isinstance(prompt, list):\n",
    "            batch_size = len(prompt)\n",
    "        else:\n",
    "            raise ValueError(f\"`prompt` has to be of type `str` or `list` but is {type(prompt)}\")\n",
    "\n",
    "        if strength < 0 or strength > 1:\n",
    "          raise ValueError(f'The value of strength should in [0.0, 1.0] but is {strength}')\n",
    "\n",
    "        # set timesteps\n",
    "        accepts_offset = \"offset\" in set(inspect.signature(self.scheduler.set_timesteps).parameters.keys())\n",
    "        extra_set_kwargs = {}\n",
    "        offset = 0\n",
    "        if accepts_offset:\n",
    "            offset = 1\n",
    "            extra_set_kwargs[\"offset\"] = 1\n",
    "\n",
    "        self.scheduler.set_timesteps(num_inference_steps, **extra_set_kwargs)\n",
    "\n",
    "        # encode the init image into latents and scale the latents\n",
    "        init_latents = self.vae.encode(init_image.to(self.device)).sample()\n",
    "        init_latents = 0.18215 * init_latents\n",
    "\n",
    "        # prepare init_latents noise to latents\n",
    "        init_latents = torch.cat([init_latents] * batch_size)\n",
    "        \n",
    "        # get the original timestep using init_timestep\n",
    "        init_timestep = int(num_inference_steps * strength) + offset\n",
    "        init_timestep = min(init_timestep, num_inference_steps)\n",
    "        timesteps = self.scheduler.timesteps[-init_timestep]\n",
    "        timesteps = torch.tensor([timesteps] * batch_size, dtype=torch.long, device=self.device)\n",
    "        \n",
    "        # add noise to latents using the timesteps\n",
    "        noise = torch.randn(init_latents.shape, generator=generator, device=self.device)\n",
    "        init_latents = self.scheduler.add_noise(init_latents, noise, timesteps)\n",
    "\n",
    "        # get prompt text embeddings\n",
    "        text_input = self.tokenizer(\n",
    "            prompt,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        text_embeddings = self.text_encoder(text_input.input_ids.to(self.device))[0]\n",
    "\n",
    "        # here `guidance_scale` is defined analog to the guidance weight `w` of equation (2)\n",
    "        # of the Imagen paper: https://arxiv.org/pdf/2205.11487.pdf . `guidance_scale = 1`\n",
    "        # corresponds to doing no classifier free guidance.\n",
    "        do_classifier_free_guidance = guidance_scale > 1.0\n",
    "        # get unconditional embeddings for classifier free guidance\n",
    "        if do_classifier_free_guidance:\n",
    "            max_length = text_input.input_ids.shape[-1]\n",
    "            uncond_input = self.tokenizer(\n",
    "                [\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\"\n",
    "            )\n",
    "            uncond_embeddings = self.text_encoder(uncond_input.input_ids.to(self.device))[0]\n",
    "\n",
    "            # For classifier free guidance, we need to do two forward passes.\n",
    "            # Here we concatenate the unconditional and text embeddings into a single batch\n",
    "            # to avoid doing two forward passes\n",
    "            text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
    "\n",
    "\n",
    "        # prepare extra kwargs for the scheduler step, since not all schedulers have the same signature\n",
    "        # eta (η) is only used with the DDIMScheduler, it will be ignored for other schedulers.\n",
    "        # eta corresponds to η in DDIM paper: https://arxiv.org/abs/2010.02502\n",
    "        # and should be between [0, 1]\n",
    "        accepts_eta = \"eta\" in set(inspect.signature(self.scheduler.step).parameters.keys())\n",
    "        extra_step_kwargs = {}\n",
    "        if accepts_eta:\n",
    "            extra_step_kwargs[\"eta\"] = eta\n",
    "\n",
    "        latents = init_latents\n",
    "        t_start = max(num_inference_steps - init_timestep + offset, 0)\n",
    "        for i, t in tqdm(enumerate(self.scheduler.timesteps[t_start:])):\n",
    "            # expand the latents if we are doing classifier free guidance\n",
    "            latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n",
    "\n",
    "            # predict the noise residual\n",
    "            noise_pred = self.unet(latent_model_input, t, encoder_hidden_states=text_embeddings)[\"sample\"]\n",
    "\n",
    "            # perform guidance\n",
    "            if do_classifier_free_guidance:\n",
    "                noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "                noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "            # compute the previous noisy sample x_t -> x_t-1\n",
    "            latents = self.scheduler.step(noise_pred, t, latents, **extra_step_kwargs)[\"prev_sample\"]\n",
    "\n",
    "        # scale and decode the image latents with vae\n",
    "        latents = 1 / 0.18215 * latents\n",
    "        image = self.vae.decode(latents)\n",
    "\n",
    "        image = (image / 2 + 0.5).clamp(0, 1)\n",
    "        image = image.cpu().permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "        # run safety checker\n",
    "        safety_cheker_input = self.feature_extractor(self.numpy_to_pil(image), return_tensors=\"pt\").to(self.device)\n",
    "        image, has_nsfw_concept = self.safety_checker(images=image, clip_input=safety_cheker_input.pixel_values)\n",
    "\n",
    "        if output_type == \"pil\":\n",
    "            image = self.numpy_to_pil(image)\n",
    "\n",
    "        return {\"sample\": image, \"nsfw_content_detected\": has_nsfw_concept}\n",
    "device = \"cuda\"\n",
    "model_path = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "from diffusers import StableDiffusionPipeline\n",
    "# Using DDIMScheduler as anexample,this also works with PNDMScheduler\n",
    "# uncomment this line if you want to use it.\n",
    "\n",
    "# scheduler = PNDMScheduler.from_config(model_path, subfolder=\"scheduler\", use_auth_token=True)\n",
    "\n",
    "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
    "img2imgpipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    model_path,\n",
    "    scheduler=scheduler,\n",
    "    revision=\"fp16\", \n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token=True\n",
    ").to(device)\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16, use_auth_token=True) \n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7dfc5e-115d-4e31-8f56-61605bebecf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T01:16:52.557401Z",
     "iopub.status.busy": "2022-08-31T01:16:52.556773Z",
     "iopub.status.idle": "2022-08-31T01:17:11.933159Z",
     "shell.execute_reply": "2022-08-31T01:17:11.932575Z",
     "shell.execute_reply.started": "2022-08-31T01:16:52.557375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Real-ESRGAN'...\n",
      "remote: Enumerating objects: 46, done.\u001b[K\n",
      "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
      "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
      "remote: Total 46 (delta 13), reused 33 (delta 5), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (46/46), 10.15 MiB | 8.26 MiB/s, done.\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from -r Real-ESRGAN/requirements.txt (line 1)) (1.23.1)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.9/dist-packages (from -r Real-ESRGAN/requirements.txt (line 2)) (4.6.0.66)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from -r Real-ESRGAN/requirements.txt (line 3)) (9.2.0)\n",
      "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from -r Real-ESRGAN/requirements.txt (line 4)) (1.12.0+cu116)\n",
      "Requirement already satisfied: torchvision>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from -r Real-ESRGAN/requirements.txt (line 5)) (0.13.0+cu116)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r Real-ESRGAN/requirements.txt (line 6)) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->-r Real-ESRGAN/requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.8.0->-r Real-ESRGAN/requirements.txt (line 5)) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.8.0->-r Real-ESRGAN/requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.8.0->-r Real-ESRGAN/requirements.txt (line 5)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision>=0.8.0->-r Real-ESRGAN/requirements.txt (line 5)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.8.0->-r Real-ESRGAN/requirements.txt (line 5)) (1.26.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading...\n",
      "From: https://drive.google.com/uc?id=1pG2S3sYvSaO0V0B8QPOl1RapPHpUGOaV\n",
      "To: /notebooks/Real-ESRGAN/Real-ESRGAN/weights/RealESRGAN_x2.pth\n",
      "100%|██████████████████████████████████████| 67.1M/67.1M [00:02<00:00, 23.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1SGHdZAln4en65_NQeQY9UjchtkEF9f5F\n",
      "To: /notebooks/Real-ESRGAN/Real-ESRGAN/weights/RealESRGAN_x4.pth\n",
      "100%|██████████████████████████████████████| 67.0M/67.0M [00:03<00:00, 21.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mT9ewx86PSrc43b-ax47l1E2UzR7Ln4j\n",
      "To: /notebooks/Real-ESRGAN/Real-ESRGAN/weights/RealESRGAN_x8.pth\n",
      "100%|██████████████████████████████████████| 67.2M/67.2M [00:03<00:00, 20.5MB/s]\n",
      "/notebooks/Real-ESRGAN/Real-ESRGAN\n",
      "device: cuda\n",
      "/notebooks/Real-ESRGAN\n"
     ]
    }
   ],
   "source": [
    "#@title Upscale\n",
    "# Соз# Prepare upscaler\n",
    "!git clone https://github.com/sberbank-ai/Real-ESRGAN\n",
    "!pip install -r Real-ESRGAN/requirements.txt\n",
    "# download model weights\n",
    "# x2 \n",
    "!gdown https://drive.google.com/uc?id=1pG2S3sYvSaO0V0B8QPOl1RapPHpUGOaV -O Real-ESRGAN/weights/RealESRGAN_x2.pth\n",
    "# x4\n",
    "!gdown https://drive.google.com/uc?id=1SGHdZAln4en65_NQeQY9UjchtkEF9f5F -O Real-ESRGAN/weights/RealESRGAN_x4.pth\n",
    "# x8\n",
    "!gdown https://drive.google.com/uc?id=1mT9ewx86PSrc43b-ax47l1E2UzR7Ln4j -O Real-ESRGAN/weights/RealESRGAN_x8.pth\n",
    "\n",
    "\n",
    "%cd Real-ESRGAN\n",
    "from realesrgan import RealESRGAN\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "\n",
    "output_upscale_factor = 2 #@param[2, 4, 8] {type:\"raw\"}\n",
    "\n",
    "model2 = RealESRGAN(device, scale = output_upscale_factor)\n",
    "model2.load_weights(f'weights/RealESRGAN_x2.pth')\n",
    "\n",
    "%cd ..\n",
    "\n",
    "def upscaleFunc(image,mult):\n",
    "    if(mult==\"2\"):\n",
    "        return model2.predict(np.array(image))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf4d1f-aee1-463a-9ea8-3b0ac5dd95c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-31T02:48:38.498218Z",
     "iopub.status.busy": "2022-08-31T02:48:38.497925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atarting listen\n",
      "Using prompt:Upscale\n",
      "New image size (512, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/1812359234.py:64: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  image = image.resize((w, h), resample = Image.LANCZOS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atarting listen\n",
      "Using prompt:Mario Kart Test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de640d06b72140f398458883db1c7ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atarting listen\n",
      "Using prompt:Upscale\n",
      "New image size (128, 128)\n",
      "atarting listen\n",
      "Using prompt:A man on mars high quality photo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1363a8c060c84a21a2c1ac4b0fffc89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atarting listen\n",
      "Using prompt:Upscale\n",
      "New image size (512, 512)\n",
      "atarting listen\n",
      "Using prompt:Upscale\n",
      "New image size (1024, 1024)\n",
      "atarting listen\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "version = \"1.1\"\n",
    "batch = 4\n",
    "from torch import autocast\n",
    "from torchvision import transforms\n",
    "import urllib3, json \n",
    "import os\n",
    "import base64\n",
    "import time\n",
    "http = urllib3.PoolManager()\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "DEFAULT_HEADERS = {'content-type': 'text/plain'}\n",
    "REQUEST_FAILED = \"Request failed\"\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "def my_preprocess(image, mask):\n",
    "    #find a way to make it work with 512-1024 dimensions, problem arises with the mask tensor\n",
    "    image = image.resize((512, 512))\n",
    "\n",
    "    w, h = image.size\n",
    "    w, h = map(lambda x: x - x % 32, (w, h))  # resize to integer multiple of 32\n",
    "    image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image)\n",
    "    return 2.0 * image - 1.0\n",
    "\n",
    "def my_preprocess_mask(mask):\n",
    "    mask = mask.convert(\"L\")\n",
    "    mask = mask.resize((64,64), resample=PIL.Image.LANCZOS)\n",
    "    mask = np.array(mask).astype(np.float32) / 255.0\n",
    "    mask = np.tile(mask,(4,1,1))\n",
    "    mask = mask[None].transpose(0, 1, 2, 3) #what does this step do?\n",
    "    mask = torch.from_numpy(mask)\n",
    "    return mask\n",
    "\n",
    "def load_img_pil(base64text):\n",
    "    temp = BytesIO()\n",
    "    \n",
    "    temp.write(base64.b64decode(base64text))\n",
    "      \n",
    "    return Image.open(temp,\"r\").convert(\"RGB\")\n",
    "def load_img(base64text, h0, w0):\n",
    "    temp = BytesIO()\n",
    "    \n",
    "    temp.write(base64.b64decode(base64text))\n",
    "    \n",
    "    image = Image.open(temp,\"r\").convert(\"RGB\")\n",
    "    w, h = image.size\n",
    "   \n",
    "    if(h0 is not None and w0 is not None):\n",
    "        h, w = h0, w0\n",
    "    \n",
    "    w, h = map(lambda x: x - x % 32, (w0, h0))  # resize to integer multiple of 32\n",
    "\n",
    "    print(f\"New image size ({w}, {h})\")\n",
    "    image = image.resize((w, h), resample = Image.LANCZOS)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image)\n",
    "    return 2.*image - 1.\n",
    "def makeHttpRequest(type, url, body = None):\n",
    "    try:\n",
    "        if type == \"GET\":\n",
    "            return http.request(\"GET\", url)\n",
    "        elif type == \"POST\":\n",
    "            return http.request(\"POST\", url, body=body, headers=DEFAULT_HEADERS)\n",
    "    except Exception as e:\n",
    "        return REQUEST_FAILED\n",
    "\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "while True:\n",
    "    print(\"atarting listen\")\n",
    "    fetchedNewPromptFromServer = False\n",
    "    while not fetchedNewPromptFromServer:\n",
    "        serverData = makeHttpRequest(\"GET\",f\"https://writerbot.selkiemyth.com/sdlist?colab=true\")\n",
    "        if serverData == REQUEST_FAILED:\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "\n",
    "        serverResponse = json.loads(serverData.data.decode(\"utf-8\"))\n",
    "        if(not \"prompt\" in serverResponse):\n",
    "           time.sleep(5)\n",
    "        else:\n",
    "            print(f\"Using prompt:{serverResponse['prompt']}\")\n",
    "            fetchedNewPromptFromServer = True\n",
    "\n",
    "    pid = serverResponse[\"id\"]\n",
    "    \n",
    "    makeHttpRequest(\"POST\", f\"https://writerbot.selkiemyth.com/update/{pid}\", body=f\"starting request in google! V{version}\")\n",
    "    width = serverResponse[\"width\"].replace(\",\",\"\")\n",
    "    height = serverResponse[\"height\"].replace(\",\",\"\")\n",
    "    iterations = serverResponse[\"iterations\"]\n",
    "    prompt = [serverResponse[\"prompt\"]]*int(iterations.replace(\",\",\"\"))\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(int(serverResponse[\"seed\"].replace(\".\",\"\")))\n",
    "    steps:str = serverResponse[\"samples\"].replace(\",\",\"\")\n",
    "    inputimg = None\n",
    "    if(\"input\" in serverResponse):\n",
    "      inputimg = load_img(serverResponse[\"input\"],int(width.replace(\",\",\"\")),int(height.replace(\",\",\"\")))\n",
    "    upscale = None\n",
    "    if(\"upscale\" in serverResponse):\n",
    "        upscale = serverResponse[\"upscale\"]\n",
    "        inputimg = load_img_pil(serverResponse[\"input\"])\n",
    "    mask = None\n",
    "    if(\"mask\" in serverResponse):\n",
    "      mask = my_preprocess_mask(load_img_pil(serverResponse[\"mask\"]))\n",
    "      inputimg = my_preprocess(load_img_pil(serverResponse[\"input\"]),mask)\n",
    "    images = []\n",
    "    with autocast(\"cuda\"):\n",
    "        \n",
    "        if(inputimg is not None):\n",
    "            if(upscale is not None):\n",
    "                images = [upscaleFunc(inputimg,upscale)]\n",
    "            else:\n",
    "                images = img2imgpipe(prompt=prompt, init_image=inputimg, strength=float(serverResponse[\"strength\"]), guidance_scale=7.5, generator=generator)[\"sample\"]\n",
    "        else:   \n",
    "            images = pipe(prompt[:3],num_inference_steps=min(int(steps.replace(\",\",\"\")),150), generator=generator, height=int(height.replace(\",\",\"\")), width=int(width.replace(\",\",\"\")))[\"sample\"] # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
    "            if(len(prompt[3:])>0):\n",
    "                makeHttpRequest(\"POST\", f\"https://writerbot.selkiemyth.com/update/{pid}\", body=f\"Iter 3-6 started\")\n",
    "            \n",
    "                images = images + pipe(prompt[3:6],num_inference_steps=min(int(steps.replace(\",\",\"\")),150), generator=generator, height=int(height.replace(\",\",\"\")), width=int(width.replace(\",\",\"\")))[\"sample\"] # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
    "            if(len(prompt[6:])>0):\n",
    "                makeHttpRequest(\"POST\", f\"https://writerbot.selkiemyth.com/update/{pid}\", body=f\"Iter 6-9 started\")\n",
    "\n",
    "                images = images + pipe(prompt[6:9],num_inference_steps=min(int(steps.replace(\",\",\"\")),150), generator=generator, height=int(height.replace(\",\",\"\")), width=int(width.replace(\",\",\"\")))[\"sample\"] # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
    "            \n",
    "    image = images[0] if (iterations == \"1\") else image_grid(images, 2, 2) if (iterations == \"4\") else image_grid(images, 3, 3)\n",
    "    # Now to display an image you can do either save it such as:\n",
    "  \n",
    "    temp = BytesIO()\n",
    "    image.save(temp,\"jpeg\")\n",
    "    encoded = base64.b64encode(temp.getvalue()).decode('utf-8')\n",
    "    saveFailed = makeHttpRequest(\"POST\", f\"https://writerbot.selkiemyth.com/upload/{pid}\", body=encoded)\n",
    "    if saveFailed == REQUEST_FAILED:\n",
    "        print(\"dammit\")\n",
    "\n",
    "    \"Finish generating images\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
